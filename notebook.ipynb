{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import show_image\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from turtle import forward\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from dataset import NMDataset\n",
    "from utils import get_train_dev_test_data\n",
    "from training import Training,validate\n",
    "from modeling import encoders,decoders,OUR_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________Create Dataset___________\n"
     ]
    }
   ],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([1024,1024]),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# create dataset \n",
    "print(\"__________Create Dataset___________\")\n",
    "train_set = NMDataset('train',transformations)\n",
    "valid_set = NMDataset('val',transformations)\n",
    "test_set = NMDataset('test',transformations)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = 3, shuffle = True)\n",
    "valid_loader = DataLoader(valid_set, batch_size = 3, shuffle = True)\n",
    "test_loader = DataLoader(test_set, batch_size = 3, shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create view_data\n",
    "for data, label in train_loader:\n",
    "  view_data = data[0:3]\n",
    "  break\n",
    "\n",
    "\n",
    "# model prepare\n",
    "model = OUR_model().cuda()\n",
    "Loss1 = nn.CrossEntropyLoss()\n",
    "Loss2 = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "print(\"____________Training_____________\")\n",
    "num_epochs = 20\n",
    "import tqdm\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    loss,loss1,loss2= Training(model,Loss1,Loss2,optimizer, train_loader)\n",
    "    val_loss,f1 = validate(model,Loss1,Loss2, valid_loader)\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "\n",
    "    ckpt_dict = {\n",
    "    'epoch': epoch + 1,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict() \n",
    "    }\n",
    "\n",
    "    torch.save(ckpt_dict, r'ckpt\\best_model_1102.pth.tar')\n",
    "\n",
    "    if epoch == 0:\n",
    "        best_rmse = loss\n",
    "    elif loss < best_rmse:\n",
    "        best_rmse = loss\n",
    "        torch.save(ckpt_dict, r'ckpt\\best_model_1102.pth.tar')\n",
    "\n",
    "\n",
    "\n",
    "    print('Epoch : {}, loss:{:.4f}, loss1:{:.4f},loss2:{:.4f},val_loss:{:.4f}, test_f1:{:.2f} {:.2f} seconds.'.format(epoch+1, loss, loss1,loss2,val_loss,f1,end_time-start_time))\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        output_decoders = []\n",
    "        conf_level,output_encoder,output_decoder = model(view_data.cuda())  \n",
    "        output_decoders.append(output_decoder)\n",
    "\n",
    "\n",
    "        f, axarr = plt.subplots(2,3,figsize= (10,6))\n",
    "        n = 0\n",
    "        for out_data, test_data in zip(output_decoder,view_data):\n",
    "            out_data = out_data.permute(1,2,0).cpu().detach().numpy()   \n",
    "            test_data  = test_data.permute(1,2,0).cpu().numpy() \n",
    "\n",
    "\n",
    "            axarr[0,n].imshow((out_data * 255).astype(np.uint8))\n",
    "            axarr[1,n].imshow((test_data * 255).astype(np.uint8))\n",
    "            n+=1\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"D:/NewEra/M\"\n",
    "A=[]\n",
    "\n",
    "for i in os.listdir(\"D:/NewEra/M\"):\n",
    "    file=i.split(\"_\")\n",
    "\n",
    "    if len(i.split(\"_\"))==3:\n",
    "        A.append(file[0]+\"_1\")\n",
    "    else:\n",
    "        A.append(file[0])\n",
    "B=list(set(A))\n",
    "print(len(B))\n",
    "train_folder = B[:28]\n",
    "val_folder = B[28:35]\n",
    "test_folder = B[35:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_file=[]\n",
    "train_folders=[]\n",
    "train_label=[]\n",
    "test_file=[]\n",
    "test_folders=[]\n",
    "test_label=[]\n",
    "val_file=[]\n",
    "val_folders=[]\n",
    "val_label=[]\n",
    "no=[]\n",
    "for file in os.listdir(path):\n",
    "\n",
    "        if len(file.split(\"_\"))==3:\n",
    "            folder_name = file.split(\"_\")[0]+\"_1\"\n",
    "        else:\n",
    "            folder_name = file.split(\"_\")[0]\n",
    "        \n",
    "        if folder_name in val_folder:\n",
    "            val_file.append([folder_name,file.split(\"_\")[-1][:-4],\"M\"])\n",
    "            # val_folders.append(folder_name)\n",
    "            # val_label.append(\"No\")\n",
    "        elif folder_name in test_folder:\n",
    "            test_file.append([folder_name,file.split(\"_\")[-1][:-4],\"M\"])\n",
    "            # test_folders.append(folder_name)\n",
    "            # test_label.append(\"No\")\n",
    "        elif folder_name in train_folder:\n",
    "            train_file.append([folder_name,file.split(\"_\")[-1][:-4],\"M\"])\n",
    "            # train_folders.append(folder_name)\n",
    "            # train_label.append(\"No\")\n",
    "        else:\n",
    "            print(folder_name)\n",
    "        \n",
    "        no.append(folder_name)\n",
    "\n",
    "\n",
    "train_df =pd.DataFrame(train_file,columns=[\"pat_id\",\"file_id\",\"label_id\"])\n",
    "val_df = pd.DataFrame(val_file,columns=[\"pat_id\",\"file_id\",\"label_id\"])\n",
    "test_df = pd.DataFrame(test_file,columns=[\"pat_id\",\"file_id\",\"label_id\"])\n",
    "train_df.to_csv(\"D:/NewEra/\" + 'M_train.csv', index=False)\n",
    "val_df.to_csv(\"D:/NewEra/\" + 'M_val.csv', index=False)\n",
    "test_df.to_csv(\"D:/NewEra/\" + 'M_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'testDataset' object has no attribute 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\micro\\Untitled-1.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/micro/Untitled-1.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m images, labels\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/micro/Untitled-1.ipynb#X15sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m realtest_set \u001b[39m=\u001b[39m testDataset(\u001b[39m'\u001b[39m\u001b[39mrealtest\u001b[39m\u001b[39m'\u001b[39m,transformations)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/micro/Untitled-1.ipynb#X15sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m realtest_loader \u001b[39m=\u001b[39m DataLoader(realtest_set, batch_size \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, shuffle \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:353\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[0;32m    352\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 353\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    354\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    355\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\sampler.py:106\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement, \u001b[39mbool\u001b[39m):\n\u001b[0;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mreplacement=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement))\n\u001b[1;32m--> 106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mvalue, but got num_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples))\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\sampler.py:114\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnum_samples\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m    112\u001b[0m     \u001b[39m# dataset size might change at runtime\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_samples \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_source)\n\u001b[0;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_samples\n",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\micro\\Untitled-1.ipynb Cell 6\u001b[0m in \u001b[0;36mtestDataset.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/micro/Untitled-1.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/micro/Untitled-1.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'testDataset' object has no attribute 'df'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class testDataset(Dataset):\n",
    "\n",
    "    def __init__(self,split,transform=None):\n",
    "        super().__init__()\n",
    "        self.path = r\"D:/NewEra\"\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        #self.df_N = pd.read_csv(self.path + '/N_'+split+'.csv')\n",
    "        self.df_M = pd.read_csv(self.path + '/M_'+split+'.csv')\n",
    "        #self.df_no = pd.read_csv(self.path + '/No_'+split+'.csv')\n",
    "        self.df = pd.concat([self.df_M],ignore_index=True) # 행 번호를 다시 0부터 쭈욱\n",
    "        self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        del(self.df_M)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def get_img(self,pat_id,file_id,label_id,patch_id=None):\n",
    "        if label_id == 'M':\n",
    "            image = cv2.imread(\"{}/M/{}_{}.png\".format(self.path, pat_id, file_id), cv2.IMREAD_COLOR)\n",
    "            image = self.transform(image)\n",
    "            label = 0\n",
    "            return image, label\n",
    "\n",
    "        elif label_id == \"N\":\n",
    "            image = cv2.imread(\"{}/N/{}_{}.png\".format(self.path , pat_id, file_id), cv2.IMREAD_COLOR)\n",
    "            image= self.transform(image)\n",
    "            label = 1\n",
    "            return image, label\n",
    "\n",
    "        else :\n",
    "            image = cv2.imread(\"{}/No/{}_{}.png\".format(self.path , pat_id, file_id), cv2.IMREAD_COLOR)\n",
    "            image= self.transform(image)\n",
    "            label = 2\n",
    "            return image, label\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pat_id, file_id, label_id = self.df.iloc[idx,:]\n",
    "        images, labels = self.get_img(pat_id, file_id,label_id)\n",
    "\n",
    "        return images, labels\n",
    "realtest_set = testDataset('realtest',transformations)\n",
    "realtest_loader = DataLoader(realtest_set, batch_size = 3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(r'ckpt\\Arts_best_checkpoint.pth.tar')\n",
    "model.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss=0\n",
    "    pred=[]\n",
    "    real=[]\n",
    "    output_decoders = []\n",
    "    for i, (data,label) in enumerate(test_loader):\n",
    "        img = data.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "        confidence,encoder,decoder = model(img)\n",
    "\n",
    "        pred += confidence.argmax(dim=1).cpu().tolist()\n",
    "        real += label.cpu().tolist()\n",
    "\n",
    "        output_decoders.append(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['Malignant', 'Normal', 'Noise']\n",
    "print(classification_report(real, pred, target_names=target_names))\n",
    "print(\"Accuarcy score : \", accuracy_score(real, pred))\n",
    "print(\"f1 score : \", f1_score(real, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "X = output_decoders.toarray()\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto',\n",
    "                   init='random', perplexity=3).fit_transform(X)\n",
    "tsne_df = pd.DataFrame(X_embedded, columns = ['component 0', 'component 1'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# class target 정보 불러오기 \n",
    "tsne_df['target'] = df['target']\n",
    "\n",
    "# target 별 분리\n",
    "tsne_df_0 = tsne_df[tsne_df['target'] == 0]\n",
    "tsne_df_1 = tsne_df[tsne_df['target'] == 1]\n",
    "tsne_df_2 = tsne_df[tsne_df['target'] == 2]\n",
    "\n",
    "# target 별 시각화\n",
    "plt.scatter(tsne_df_0['component 0'], tsne_df_0['component 1'], color = 'pink', label = 'setosa')\n",
    "plt.scatter(tsne_df_1['component 0'], tsne_df_1['component 1'], color = 'purple', label = 'versicolor')\n",
    "plt.scatter(tsne_df_2['component 0'], tsne_df_2['component 1'], color = 'yellow', label = 'virginica')\n",
    "\n",
    "plt.xlabel('component 0')\n",
    "plt.ylabel('component 1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "encoder22= nn.Sequential(\n",
    "    nn.Conv2d(3, 32, 3, stride=3, padding=1),  # b, 3, 10, 10\n",
    "    nn.ReLU(True),\n",
    "# b, 16, 5, 5\n",
    "    nn.Conv2d(32, 32, 3, stride=3, padding=1),  # b, 8, 3, 3\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Conv2d(32, 8, 3, stride=3, padding=1),  # b, 8, 3, 3\n",
    "    nn.ReLU(True),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(11552,2)\n",
    "    )# b, 8, 2, 2\n",
    "    \n",
    "\n",
    "decoder22 = nn.Sequential(\n",
    "            \n",
    "            \n",
    "    nn.ConvTranspose2d(8, 32, 5, stride=3, padding=1),  # b, 16, 5, 5\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(32, 32, 5, stride=3, padding=0),  # b, 8, 15, 15\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(32, 3, 3, stride=3, padding=4),  # b, 1, 28, 28\n",
    "    nn.Tanh())\n",
    "\n",
    "x= torch.rand(2,3,1024,1024)\n",
    "y = torch.rand(2,2)\n",
    "En = encoder22(x)\n",
    "linear = nn.Linear(2,11552)\n",
    "En = linear(En)\n",
    "En = En.view(-1,8,38,38)\n",
    "de = decoder22(En )\n",
    "print(En.size(),de.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a911b5aa042724ead966489e6f5164935952a049f40d7a798c17a648930e160"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
